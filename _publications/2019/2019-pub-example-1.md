---
title:          "Learning Linear Transformations for Fast Image and Video Style Transfer"
date:           2019-06-12 00:01:00 +0800
pub:            "Computer Vision and Pattern Recognition (CVPR)"
# pub_pre:        "Submitted to "
# pub_post:       'Under review.'
pub_date:       "2019"

abstract: >-
  Given a random pair of images, a universal style transfer method extracts the feel from a reference image to synthesize an output based on the look of a content image. Recent algorithms based on second-order statistics, however, are either computationally expensive or prone to generate artifacts due to the trade-off between image quality and runtime performance. In this work, we present an approach for universal style transfer that learns the transformation matrix in a data-driven fashion. Our algorithm is efficient yet flexible to transfer different levels of styles with the same auto-encoder network. It also produces stable video style transfer results due to the preservation of the content affinity. In addition, we propose a linear propagation module to enable a feed-forward network for photo-realistic style transfer. We demonstrate the effectiveness of our approach on three tasks: artistic style, photo-realistic and video style transfer, with comparisons to state-of-the-art methods.
#cover:          /assets/images/covers/cover3.jpg
authors:
  - Xueting Li
  - Sifei Liu
  - Jan Kautz
  - Ming-Hsuan Yang
links:
  Code: https://github.com/sunshineatnoon/LinearStyleTransfer
---
